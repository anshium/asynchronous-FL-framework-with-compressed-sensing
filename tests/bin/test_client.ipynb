{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3836cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import your local modules\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n",
    "\n",
    "from fedasynccs.compression import CSCompressor\n",
    "import fedasynccs.dataset as dataset\n",
    "import fedasynccs.models as models\n",
    "\n",
    "# --- Configuration ---\n",
    "CONFIG = {\n",
    "    'dataset': 'mnist',\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.05,           # Higher LR often helps CS methods overcome noise\n",
    "    'epochs': 10,          # Keep it short for testing\n",
    "    'compression_ratio': 0.1,\n",
    "    'subset_size': 1000,  # Use a subset to speed up the slow CS reconstruction\n",
    "    'device': models.get_device()\n",
    "}\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    \"\"\"Evaluates the model on the test set.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "def run_simulation(mode, train_loader, test_loader, original_model):\n",
    "    \"\"\"\n",
    "    Runs a training simulation for a specific mode: 'baseline', 'cs-fl', '1bit-cs-fl'.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Simulation: {mode.upper()} ---\")\n",
    "    \n",
    "    # Clone the model so everyone starts from the exact same weights\n",
    "    model = copy.deepcopy(original_model).to(CONFIG['device'])\n",
    "    \n",
    "    # Count parameters\n",
    "    flat_params = torch.cat([p.data.view(-1) for p in model.parameters()])\n",
    "    total_params = flat_params.numel()\n",
    "    \n",
    "    # Initialize Compressor (only used for CS modes)\n",
    "    compressor = None\n",
    "    residual = None\n",
    "    \n",
    "    if mode != 'baseline':\n",
    "        print(f\"Initializing Compressor (Ratio: {CONFIG['compression_ratio']})...\")\n",
    "        compressor = CSCompressor(total_params, CONFIG['compression_ratio'], device=CONFIG['device'])\n",
    "        # Residual must be a Tensor on the correct device\n",
    "        residual = torch.zeros(total_params, device=CONFIG['device'])\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=CONFIG['lr'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(1, CONFIG['epochs'] + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(CONFIG['device']), target.to(CONFIG['device'])\n",
    "            \n",
    "            # 1. Standard Forward/Backward\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # 2. Apply Updates based on Mode\n",
    "            if mode == 'baseline':\n",
    "                # Standard SGD\n",
    "                optimizer.step()\n",
    "                \n",
    "            else:\n",
    "                # --- Simulate Client-Server CS Loop ---\n",
    "                \n",
    "                # A. Get Gradients as a flat vector\n",
    "                grads = []\n",
    "                for p in model.parameters():\n",
    "                    if p.grad is not None:\n",
    "                        grads.append(p.grad.view(-1))\n",
    "                    else:\n",
    "                        grads.append(torch.zeros(p.numel(), device=CONFIG['device']))\n",
    "                flat_grad = torch.cat(grads)\n",
    "                \n",
    "                # B. Client: Compress\n",
    "                # We compress the gradient vector directly\n",
    "                seed = int(time.time() * 100000) % 100000\n",
    "                use_1bit = (mode == '1bit-cs-fl')\n",
    "                \n",
    "                payload, new_residual = compressor.compress(\n",
    "                    update_vector=flat_grad,\n",
    "                    residual_vector=residual,\n",
    "                    seed=seed,\n",
    "                    use_1bit=use_1bit\n",
    "                )\n",
    "                \n",
    "                residual = new_residual # Update client memory\n",
    "                \n",
    "                # C. Server: Reconstruct\n",
    "                # (Simulating the server receiving the payload)\n",
    "                reconstructed_grad = compressor.reconstruct(\n",
    "                    payload=payload,\n",
    "                    seed=seed,\n",
    "                    use_1bit=use_1bit,\n",
    "                    iterations=50 # Lower iterations for speed in test\n",
    "                )\n",
    "                \n",
    "                # D. Update Model Weights\n",
    "                # Apply the noisy reconstructed update: w = w - lr * reconstructed_grad\n",
    "                offset = 0\n",
    "                with torch.no_grad():\n",
    "                    for p in model.parameters():\n",
    "                        numel = p.numel()\n",
    "                        if p.grad is not None:\n",
    "                            layer_update = reconstructed_grad[offset:offset+numel].view(p.shape)\n",
    "                            p.data.sub_(CONFIG['lr'] * layer_update)\n",
    "                        offset += numel\n",
    "\n",
    "        # End of Epoch Metrics\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        # Test Accuracy\n",
    "        acc = test_model(model, test_loader, CONFIG['device'])\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch} | Loss: {avg_loss:.4f} | Acc: {acc:.2f}%\")\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Finished {mode.upper()} in {duration:.2f}s\")\n",
    "    return losses, accuracies\n",
    "\n",
    "def plot_results(results):\n",
    "    \"\"\"Plots comparison graphs.\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for mode, data in results.items():\n",
    "        plt.plot(range(1, CONFIG['epochs'] + 1), data['acc'], label=mode, marker='o')\n",
    "    plt.title(f\"Test Accuracy (Ratio: {CONFIG['compression_ratio']})\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for mode, data in results.items():\n",
    "        plt.plot(range(1, CONFIG['epochs'] + 1), data['loss'], label=mode, marker='o')\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"Plot generated.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"=== Simulation Config ===\")\n",
    "    print(f\"Dataset: {CONFIG['dataset']}\")\n",
    "    print(f\"Device: {CONFIG['device']}\")\n",
    "    print(f\"Compression Ratio: {CONFIG['compression_ratio']}\")\n",
    "    print(f\"Note: Using subset of {CONFIG['subset_size']} samples for speed.\")\n",
    "    \n",
    "    # 1. Prepare Data\n",
    "    train_ds, test_ds = dataset.get_dataset(CONFIG['dataset'])\n",
    "    \n",
    "    # Subset for speed\n",
    "    indices = list(range(CONFIG['subset_size']))\n",
    "    train_loader = dataset.get_dataloader(train_ds, indices, CONFIG['batch_size'])\n",
    "    test_loader = torch.utils.data.DataLoader(test_ds, batch_size=500, shuffle=False)\n",
    "    \n",
    "    # 2. Prepare Base Model\n",
    "    base_model = models.get_model(CONFIG['dataset'])\n",
    "    \n",
    "    # 3. Run Experiments\n",
    "    results = {}\n",
    "    \n",
    "    # Experiment A: Baseline\n",
    "    loss, acc = run_simulation('baseline', train_loader, test_loader, base_model)\n",
    "    results['baseline'] = {'loss': loss, 'acc': acc}\n",
    "    \n",
    "    # Experiment B: CS-FL (Analog)\n",
    "    loss, acc = run_simulation('cs-fl', train_loader, test_loader, base_model)\n",
    "    results['cs-fl'] = {'loss': loss, 'acc': acc}\n",
    "    \n",
    "    # Experiment C: 1-Bit CS-FL\n",
    "    loss, acc = run_simulation('1bit-cs-fl', train_loader, test_loader, base_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
